{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_JwpMDrMeVX"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L103htgKKSYZ"
      },
      "outputs": [],
      "source": [
        "# Initialize Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "!pip install -U sentence_transformers\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYUhIv5AKT6x"
      },
      "outputs": [],
      "source": [
        "# To save and read data files from your Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VQHrck2Mnxy"
      },
      "source": [
        "# Load and explore the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z7uLzJeKclP"
      },
      "outputs": [],
      "source": [
        "# Import the news.tsv file\n",
        "path = '/content/drive/MyDrive/2024 Spring/Text Mining/Projects/Project4/'\n",
        "news_df = pd.read_csv(path+'news.tsv', sep='\\t', header = None)\n",
        "news_df.columns = ['News_ID', 'Category', 'Subcategory', 'Title', 'Abstract', 'URL', 'Title_entities', 'Abstract_entities']\n",
        "news_df.info()\n",
        "news_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df.to_csv(path + 'news.tsv', sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "uMFvSvNBopSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK1_ORxKKosy"
      },
      "outputs": [],
      "source": [
        "# Import the behavior.tsv file\n",
        "behaviors_df = pd.read_csv(path+'behaviors.tsv', sep='\\t', header = None)\n",
        "behaviors_df.columns = ['Impression_ID', 'User_ID','Time', 'History','Impressions']\n",
        "behaviors_df.info()\n",
        "behaviors_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4udD63T5Mjso"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30obUwPXQDY5"
      },
      "outputs": [],
      "source": [
        "# Make a dictionary for the text (embeddings will include the title, abstract, category, and subcategory)\n",
        "news_text_dict = {\n",
        "    row['News_ID']: f\"{row['Title']} {row['Abstract']} {row['Category']} {row['Subcategory']}\"\n",
        "    for _, row in news_df.iterrows()\n",
        "}\n",
        "# news_text_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxWVfU0lKuH0"
      },
      "outputs": [],
      "source": [
        "# For the behavior file\n",
        "\n",
        "# Delete all the rows that either don't have any history or don't have impresssions\n",
        "behaviors_df = behaviors_df.dropna(subset=[\"History\", \"Impressions\"])\n",
        "\n",
        "# Make a newer table consisting of user, last_news, recommendation, and clicked\n",
        "behavior_table_rows = []\n",
        "\n",
        "for index, row in behaviors_df.iterrows():\n",
        "  for impression in row['Impressions'].split():\n",
        "    id = row['User_ID']\n",
        "    last_news = row['History'].split()[-1]\n",
        "    recommendation = impression.split('-')[0]\n",
        "    clicked = impression.split('-')[1]\n",
        "    behavior_table_rows.append([id, last_news, recommendation, clicked])\n",
        "\n",
        "behavior_table = pd.DataFrame(behavior_table_rows, columns=['id', 'last_news', 'recommendation', 'clicked'])\n",
        "behavior_table.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the text to the feature\n",
        "behavior_table[\"last_news_text\"] = behavior_table[\"last_news\"].map(news_text_dict)\n",
        "behavior_table[\"recommendation_text\"] = behavior_table[\"recommendation\"].map(news_text_dict)\n",
        "behavior_table.head()"
      ],
      "metadata": {
        "id": "PtEd4ZMIo3uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ydTZlTYoNcU"
      },
      "source": [
        "# Create Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtyUTHQBRIQj"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zt0EILCq9IQ"
      },
      "outputs": [],
      "source": [
        "# For the Behavior file\n",
        "last_news_list = behavior_table['last_news_text'].astype(str).tolist()\n",
        "recommend = behavior_table['recommendation_text'].astype(str).tolist()\n",
        "\n",
        "news_embeddings_path = path + 'last_news_embeddings.npy'\n",
        "recommend_embeddings_path = path + 'recommend_embeddings.npy'\n",
        "\n",
        "# If embeddings exist, load them. If they don't, make them.\n",
        "if os.path.exists(news_embeddings_path):\n",
        "  last_news_embeddings = np.load(news_embeddings_path)\n",
        "  del last_news_list\n",
        "  gc.collect()\n",
        "else:\n",
        "  last_news_embeddings = model.encode(last_news_list, batch_size=32, show_progress_bar=True)\n",
        "  np.save(news_embeddings_path, last_news_embeddings)\n",
        "\n",
        "# If embeddings exist, load them. If they don't, make them.\n",
        "if os.path.exists(recommend_embeddings_path):\n",
        "  recommend_embeddings = np.load(recommend_embeddings_path)\n",
        "  del recommend\n",
        "  gc.collect()\n",
        "else:\n",
        "  recommend_embeddings = model.encode(recommend, batch_size=32, show_progress_bar=True)\n",
        "  np.save(recommend_embeddings_path, recommend_embeddings)\n",
        "\n",
        "last_news_embeddings.shape\n",
        "recommend_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determine Scores!"
      ],
      "metadata": {
        "id": "_nA8F5htkhu2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-oiY_xju6Sc"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import norm\n",
        "\n",
        "behavior_scored_path = path + 'behavior_scored.pkl'\n",
        "\n",
        "# Cosine Similarity\n",
        "if os.path.exists(behavior_scored_path):\n",
        "    behavior_table = pd.read_pickle(behavior_scored_path)\n",
        "else:\n",
        "    dot_products = np.sum(last_news_embeddings * recommend_embeddings, axis=1)\n",
        "    norms = norm(last_news_embeddings, axis=1) * norm(recommend_embeddings, axis=1)\n",
        "    cosine_scores = dot_products / norms\n",
        "\n",
        "    behavior_table[\"cosine_score\"] = cosine_scores\n",
        "    behavior_table.to_pickle(behavior_scored_path)\n",
        "\n",
        "behavior_table[\"clicked\"] = behavior_table[\"clicked\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "behavior_table"
      ],
      "metadata": {
        "id": "qC9FDef7kkBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision @ n and MRR function\n",
        "def precision_and_mrr(df, n):\n",
        "    clicked = 0\n",
        "    counted = 0\n",
        "    scores = []\n",
        "    for index, group in df.groupby(\"id\"):  # id = user_id\n",
        "        top_n = group.sort_values(\"cosine_score\", ascending=False).head(n)\n",
        "        if top_n[\"clicked\"].sum() > 0:\n",
        "            clicked += 1\n",
        "        counted += 1\n",
        "\n",
        "        sorted = group.sort_values(\"cosine_score\", ascending=False).reset_index(drop=True)\n",
        "        for index_2, row in sorted.iterrows():\n",
        "          if row[\"clicked\"] == 1:\n",
        "            scores.append(1 / (index_2 + 1))\n",
        "            break\n",
        "        else:\n",
        "          scores.append[0]\n",
        "\n",
        "    return clicked / counted if counted > 0 else 0, sum(scores) / len(scores)\n",
        "\n",
        "\n",
        "n=10\n",
        "precision, mrr = precision_and_mrr(behavior_table, n)\n",
        "print(f\"Precision @ {n} : {precision:.4f}\")\n",
        "print(f\"MRR : {mrr:.4f}\")"
      ],
      "metadata": {
        "id": "FtL_n1xLpBcT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "y_JwpMDrMeVX",
        "_VQHrck2Mnxy",
        "4udD63T5Mjso",
        "5ydTZlTYoNcU",
        "_nA8F5htkhu2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}